{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Number_plate_detection.ipynb","provenance":[],"collapsed_sections":["__OBg22TtyYW","VqxkFCRF-IoV","96pTDeMEZBon","sIeU0Vyy7lSy","eePdeg01N-CD"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"__OBg22TtyYW","colab_type":"text"},"source":["# Submission details\n","*   **Group**: 45 \n","*   **Name**: Aditya Verma 12948511, Elena Varelas 12567487, Jenny Nguyen 12948461\n","*   **Task**: Vehicle Number plate Object detection\n","*   **Subject**: 42028 Deep Learning and Convolutional Neural Network - Autumn 2020\n","*   **DataSet**: Isreal Dataset\n","*   **CNN Used**: Multiple\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"5-9WVB1m1hGY","colab_type":"text"},"source":["Donwloaded the required packages "]},{"cell_type":"code","metadata":{"id":"9FCE9LMlEbwl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1592282802147,"user_tz":-600,"elapsed":3467,"user":{"displayName":"Aditya Verma","photoUrl":"","userId":"11441793658136875754"}},"outputId":"d02976d8-66eb-4e48-bb4a-e038410e9936"},"source":["%tensorflow_version 1.x\n","!pip install numpy==1.17.4"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","Requirement already satisfied: numpy==1.17.4 in /usr/local/lib/python3.6/dist-packages (1.17.4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4gK7IBSQpc3d","colab_type":"code","colab":{}},"source":["import re\n","import numpy as np\n","\n","import os\n","from glob import glob\n","import shutil\n","\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","\n","import tensorflow.compat.v1 as tf "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CE9DPHA01q9o","colab_type":"text"},"source":["Mounted the drive so we could easily access our files"]},{"cell_type":"code","metadata":{"id":"_pNPTFjy_brC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":118},"executionInfo":{"status":"ok","timestamp":1592282845614,"user_tz":-600,"elapsed":43457,"user":{"displayName":"Aditya Verma","photoUrl":"","userId":"11441793658136875754"}},"outputId":"3c38a7ea-1ef6-44cb-f60d-6d098ddc8c0e"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8p2ebGmG_ZUs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1592282845614,"user_tz":-600,"elapsed":3927,"user":{"displayName":"Aditya Verma","photoUrl":"","userId":"11441793658136875754"}},"outputId":"ed0c08bf-1d98-4223-e8e5-688ad445580a"},"source":["%cd /content/gdrive/My Drive/assign3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/assign3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VqxkFCRF-IoV","colab_type":"text"},"source":["#1 Download Dataset"]},{"cell_type":"code","metadata":{"id":"EKdgq3TL-563","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":141},"executionInfo":{"status":"ok","timestamp":1591705874027,"user_tz":-600,"elapsed":6859,"user":{"displayName":"Aditya Verma","photoUrl":"","userId":"11441793658136875754"}},"outputId":"134dc86c-ce4b-4d4c-c13f-16ecf1b2c233"},"source":["!pip install requests; pip install pillow"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.23.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2020.4.5.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.9)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (7.0.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FpN6Y3hF1yG5","colab_type":"text"},"source":["Downloaded the dataset into the appropriate folders"]},{"cell_type":"code","metadata":{"id":"EH0vU-tUCmhI","colab_type":"code","colab":{}},"source":["import os\n","image_download_folder = os.path.join(os.getcwd(),'Images')\n","pascal_voc_out_folder = os.path.join(os.getcwd(),'Pascal_Voc')\n","filepath = 'Israeli_license_plates.json'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V-ig6BbxtoFl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1591707041933,"user_tz":-600,"elapsed":424134,"user":{"displayName":"Aditya Verma","photoUrl":"","userId":"11441793658136875754"}},"outputId":"c4285c2a-b904-4527-f1d8-8fd8c5d4f25c"},"source":["!python dataturks_to_PascalVOC.py $filepath ./Images ./Pascal_Voc/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:root:10 items done ...\n","INFO:root:20 items done ...\n","INFO:root:30 items done ...\n","INFO:root:40 items done ...\n","INFO:root:50 items done ...\n","INFO:root:60 items done ...\n","INFO:root:70 items done ...\n","INFO:root:80 items done ...\n","INFO:root:90 items done ...\n","INFO:root:100 items done ...\n","INFO:root:110 items done ...\n","INFO:root:120 items done ...\n","INFO:root:130 items done ...\n","INFO:root:140 items done ...\n","INFO:root:150 items done ...\n","INFO:root:160 items done ...\n","INFO:root:170 items done ...\n","INFO:root:180 items done ...\n","INFO:root:190 items done ...\n","INFO:root:200 items done ...\n","INFO:root:210 items done ...\n","INFO:root:220 items done ...\n","INFO:root:230 items done ...\n","INFO:root:240 items done ...\n","INFO:root:250 items done ...\n","INFO:root:260 items done ...\n","INFO:root:270 items done ...\n","INFO:root:280 items done ...\n","INFO:root:290 items done ...\n","INFO:root:300 items done ...\n","INFO:root:310 items done ...\n","INFO:root:320 items done ...\n","INFO:root:330 items done ...\n","INFO:root:340 items done ...\n","INFO:root:350 items done ...\n","INFO:root:360 items done ...\n","INFO:root:370 items done ...\n","INFO:root:380 items done ...\n","INFO:root:390 items done ...\n","INFO:root:400 items done ...\n","INFO:root:410 items done ...\n","INFO:root:420 items done ...\n","INFO:root:430 items done ...\n","INFO:root:440 items done ...\n","INFO:root:450 items done ...\n","INFO:root:460 items done ...\n","INFO:root:Ignoring Skipped Item\n","INFO:root:470 items done ...\n","INFO:root:480 items done ...\n","INFO:root:490 items done ...\n","INFO:root:500 items done ...\n","INFO:root:510 items done ...\n","INFO:root:520 items done ...\n","INFO:root:530 items done ...\n","INFO:root:540 items done ...\n","INFO:root:550 items done ...\n","INFO:root:560 items done ...\n","INFO:root:570 items done ...\n","INFO:root:580 items done ...\n","INFO:root:590 items done ...\n","INFO:root:600 items done ...\n","INFO:root:610 items done ...\n","INFO:root:620 items done ...\n","INFO:root:630 items done ...\n","INFO:root:640 items done ...\n","INFO:root:650 items done ...\n","INFO:root:660 items done ...\n","INFO:root:Completed: 664 items done, 1 items ignored due to errors or for being skipped items.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"96pTDeMEZBon","colab_type":"text"},"source":["#2 Model"]},{"cell_type":"markdown","metadata":{"id":"yl62iIOR2X_n","colab_type":"text"},"source":["Set up training parameters for the model and selected the model type (changed model type for each experiment)"]},{"cell_type":"code","metadata":{"id":"keArxBC5ZEhu","colab_type":"code","colab":{}},"source":["# If you forked the repository, you can replace the link.\n","repo_url = 'https://github.com/Tony607/object_detection_demo'\n","\n","# Number of training steps.\n","num_steps = 5000  # 200000\n","\n","# Number of evaluation steps.\n","num_eval_steps = 50\n","\n","MODELS_CONFIG = {\n","    'ssd_mobilenet_v2': {\n","        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n","        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n","        'batch_size': 12\n","    },\n","    'faster_rcnn_inception_v2': {\n","        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n","        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n","        'batch_size': 12\n","    },\n","    'rfcn_resnet101': {\n","        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n","        'pipeline_file': 'rfcn_resnet101_pets.config',\n","        'batch_size': 12\n","    }\n","}\n","\n","# Pick the model you want to use\n","\n","selected_model = 'ssd_mobilenet_v2'\n","\n","# Name of the object detection model to use.\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\n","\n","# Name of the pipline file in tensorflow object detection API.\n","pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n","\n","# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n","batch_size = MODELS_CONFIG[selected_model]['batch_size']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m4FQVFKAZGSn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":82},"executionInfo":{"status":"ok","timestamp":1592282853168,"user_tz":-600,"elapsed":7822,"user":{"displayName":"Aditya Verma","photoUrl":"","userId":"11441793658136875754"}},"outputId":"0704daca-623f-4f1f-eccd-19743bfd05cb"},"source":["%cd /content/gdrive/My Drive/assign3\n","\n","repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n","\n","!git clone {repo_url}\n","%cd {repo_dir_path}\n","!git pull"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/assign3\n","fatal: destination path 'object_detection_demo' already exists and is not an empty directory.\n","/content/gdrive/My Drive/assign3/object_detection_demo\n","Already up to date.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"M71jpqcJ2x5U","colab_type":"text"},"source":["DOwnloaded pre-trained models "]},{"cell_type":"code","metadata":{"id":"dO87WpfWZIxe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592282892911,"user_tz":-600,"elapsed":46502,"user":{"displayName":"Aditya Verma","photoUrl":"","userId":"11441793658136875754"}},"outputId":"423c389c-e259-4bd4-99c1-1534b847c292"},"source":["%cd /content\n","\n","#!git clone --quiet https://github.com/tensorflow/models.git\n","\n","!git clone --branch r1.13.0 --depth 1 https://github.com/tensorflow/models.git\n","\n","\n","!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n","\n","!pip install -q Cython contextlib2 pillow lxml matplotlib\n","\n","!pip install -q pycocotools\n","\n","%cd /content/models/research\n","!protoc object_detection/protos/*.proto --python_out=.\n","\n","import os\n","os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n","\n","!python object_detection/builders/model_builder_test.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n","Cloning into 'models'...\n","remote: Enumerating objects: 2927, done.\u001b[K\n","remote: Counting objects: 100% (2927/2927), done.\u001b[K\n","remote: Compressing objects: 100% (2449/2449), done.\u001b[K\n","remote: Total 2927 (delta 509), reused 2035 (delta 403), pack-reused 0\u001b[K\n","Receiving objects: 100% (2927/2927), 369.04 MiB | 39.80 MiB/s, done.\n","Resolving deltas: 100% (509/509), done.\n","Checking out files: 100% (2768/2768), done.\n","Selecting previously unselected package python-bs4.\n","(Reading database ... 144328 files and directories currently installed.)\n","Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n","Unpacking python-bs4 (4.6.0-1) ...\n","Selecting previously unselected package python-pkg-resources.\n","Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n","Unpacking python-pkg-resources (39.0.1-2) ...\n","Selecting previously unselected package python-chardet.\n","Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n","Unpacking python-chardet (3.0.4-1) ...\n","Selecting previously unselected package python-six.\n","Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n","Unpacking python-six (1.11.0-2) ...\n","Selecting previously unselected package python-webencodings.\n","Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n","Unpacking python-webencodings (0.5-2) ...\n","Selecting previously unselected package python-html5lib.\n","Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n","Unpacking python-html5lib (0.999999999-1) ...\n","Selecting previously unselected package python-lxml:amd64.\n","Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n","Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n","Selecting previously unselected package python-olefile.\n","Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n","Unpacking python-olefile (0.45.1-1) ...\n","Selecting previously unselected package python-pil:amd64.\n","Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.2_amd64.deb ...\n","Unpacking python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n","Setting up python-pkg-resources (39.0.1-2) ...\n","Setting up python-six (1.11.0-2) ...\n","Setting up python-bs4 (4.6.0-1) ...\n","Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n","Setting up python-olefile (0.45.1-1) ...\n","Setting up python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n","Setting up python-webencodings (0.5-2) ...\n","Setting up python-chardet (3.0.4-1) ...\n","Setting up python-html5lib (0.999999999-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","/content/models/research\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/models/research/slim/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","WARNING:tensorflow:From /content/models/research/slim/nets/mobilenet/mobilenet.py:389: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n","\n","Running tests under Python 3.6.9: /usr/bin/python3\n","[ RUN      ] ModelBuilderTest.test_create_embedded_ssd_mobilenet_v1_model_from_config\n","[       OK ] ModelBuilderTest.test_create_embedded_ssd_mobilenet_v1_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_inception_resnet_v2_model_from_config\n","WARNING:tensorflow:From /content/models/research/object_detection/anchor_generators/grid_anchor_generator.py:59: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0616 04:48:11.301875 140075436455808 deprecation.py:323] From /content/models/research/object_detection/anchor_generators/grid_anchor_generator.py:59: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_inception_resnet_v2_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_inception_v2_model_from_config\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_inception_v2_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_nas_model_from_config\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_nas_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_pnas_model_from_config\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_pnas_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_resnet101_with_mask_prediction_enabled(use_matmul_crop_and_resize=False)\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_resnet101_with_mask_prediction_enabled(use_matmul_crop_and_resize=False)\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_resnet101_with_mask_prediction_enabled(use_matmul_crop_and_resize=True)\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_resnet101_with_mask_prediction_enabled(use_matmul_crop_and_resize=True)\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_resnet_v1_models_from_config\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_resnet_v1_models_from_config\n","[ RUN      ] ModelBuilderTest.test_create_rfcn_resnet_v1_model_from_config\n","[       OK ] ModelBuilderTest.test_create_rfcn_resnet_v1_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_inception_v2_model_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_inception_v2_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_inception_v3_model_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_inception_v3_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_mobilenet_v1_fpn_model_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_mobilenet_v1_fpn_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_mobilenet_v1_model_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_mobilenet_v1_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_mobilenet_v1_ppn_model_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_mobilenet_v1_ppn_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_mobilenet_v2_fpn_model_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_mobilenet_v2_fpn_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_mobilenet_v2_fpnlite_model_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_mobilenet_v2_fpnlite_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_mobilenet_v2_keras_model_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_mobilenet_v2_keras_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_mobilenet_v2_model_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_mobilenet_v2_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_resnet_v1_fpn_model_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_resnet_v1_fpn_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_resnet_v1_ppn_model_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_resnet_v1_ppn_model_from_config\n","[ RUN      ] ModelBuilderTest.test_session\n","[  SKIPPED ] ModelBuilderTest.test_session\n","----------------------------------------------------------------------\n","Ran 22 tests in 0.099s\n","\n","OK (skipped=1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sIeU0Vyy7lSy","colab_type":"text"},"source":["#3 Preparing tfrecord files"]},{"cell_type":"markdown","metadata":{"id":"eePdeg01N-CD","colab_type":"text"},"source":["##3.x MANUALLY move Images and corresponding xml\n","I have manually moved the images and xml files into seperate folders.\n","The split format is roughly 90% Training to 10% Test(51 Images).\n","Images and xml ranging from 00000 to 00351 have been moved to /images/train. And the rest have been moved to /images/test/."]},{"cell_type":"markdown","metadata":{"id":"_ZNMbqOYG43k","colab_type":"text"},"source":["Overwrites existing image folder with the blood images"]},{"cell_type":"code","metadata":{"id":"p7G1lPjxZO5g","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1591957223343,"user_tz":-600,"elapsed":1043,"user":{"displayName":"Aditya Verma","photoUrl":"","userId":"11441793658136875754"}},"outputId":"cb302dc6-01d5-4261-85ee-4b8f118f622a"},"source":["%cd /content/gdrive/My Drive/assign3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/assign3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ukqxN2KF-oIL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1591708651800,"user_tz":-600,"elapsed":2802,"user":{"displayName":"Aditya Verma","photoUrl":"","userId":"11441793658136875754"}},"outputId":"0740bee6-d8b5-42c3-bf8a-988586db1adf"},"source":["#Moves the images into the demo github repo\n","!mv images object_detection_demo/data/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["mv: cannot stat 'images': No such file or directory\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mY_hqbKLir9q","colab_type":"text"},"source":["##3.1 Creating tf records and label maps"]},{"cell_type":"code","metadata":{"id":"S9PJUm7VTolC","colab_type":"code","colab":{}},"source":["!protoc object_detection/protos/*.proto --python_out=."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LYJWy5H_AfOh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":82},"executionInfo":{"status":"ok","timestamp":1592283049854,"user_tz":-600,"elapsed":198090,"user":{"displayName":"Aditya Verma","photoUrl":"","userId":"11441793658136875754"}},"outputId":"a63863c3-df90-4e66-be56-00730def930f"},"source":["%cd {repo_dir_path}\n","\n","# Using the xml to cxs python file to convert the annotations in the \n","# training folder to csv files in preperation for training\n","# It will also be creating a label map\n","!python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n","\n","# to generate the csv file for the test images\n","!python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/assign3/object_detection_demo\n","Successfully converted xml to csv.\n","Generate `data/annotations/label_map.pbtxt`\n","Successfully converted xml to csv.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SznrTjwoSBjR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":687},"executionInfo":{"status":"ok","timestamp":1592283157648,"user_tz":-600,"elapsed":304678,"user":{"displayName":"Aditya Verma","photoUrl":"","userId":"11441793658136875754"}},"outputId":"c51e5811-0445-4891-9c96-5c9df05728e4"},"source":["%cd {repo_dir_path}\n","# tf records are required for the labels so that the model can train. \n","# The python file generate tfrecords from the tf model dir is being used\n","!python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n","\n","# tf records are required for the labels so that the model can train. \n","# The python file generate tfrecords from the tf model dir is being used\n","!python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/assign3/object_detection_demo\n","WARNING:tensorflow:From generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","W0616 04:50:52.109442 140173062334336 module_wrapper.py:139] From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/label_map_util.py:132: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0616 04:50:52.845963 140173062334336 module_wrapper.py:139] From /content/models/research/object_detection/utils/label_map_util.py:132: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","Traceback (most recent call last):\n","  File \"generate_tfrecord.py\", line 134, in <module>\n","    tf.app.run()\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n","    sys.exit(main(argv))\n","  File \"generate_tfrecord.py\", line 125, in main\n","    tf_example = create_tf_example(group, path, label_map)\n","  File \"generate_tfrecord.py\", line 54, in create_tf_example\n","    encoded_jpg = fid.read()\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/lib/io/file_io.py\", line 122, in read\n","    self._preread_check()\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/lib/io/file_io.py\", line 84, in _preread_check\n","    compat.as_bytes(self.__name), 1024 * 512)\n","tensorflow.python.framework.errors_impl.NotFoundError: /content/gdrive/My Drive/assign3/object_detection_demo/data/images/train/b438ee9a-db6b-4043-8a08-3714b1d7ee1b___ANPR_Dubai_edited_J26A.jpeg; No such file or directory\n","WARNING:tensorflow:From generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","W0616 04:52:09.497507 140419968731008 module_wrapper.py:139] From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/label_map_util.py:132: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0616 04:52:09.975838 140419968731008 module_wrapper.py:139] From /content/models/research/object_detection/utils/label_map_util.py:132: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","Successfully created the TFRecords: /content/gdrive/My Drive/assign3/object_detection_demo/data/annotations/test.record\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yGC_049huurK","colab_type":"text"},"source":["##3.2 Initializing directories "]},{"cell_type":"code","metadata":{"id":"LWgy6-7VHA6b","colab_type":"code","colab":{}},"source":["test_record_fname = '/content/gdrive/My Drive/assign3//object_detection_demo/data/annotations/test.record'\n","train_record_fname = '/content/gdrive/My Drive/assign3/object_detection_demo/data/annotations/train.record'\n","label_map_pbtxt_fname = '/content/gdrive/My Drive/assign3/object_detection_demo/data/annotations/label_map.pbtxt'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NOqwSDK7g3Gy"},"source":["#4 Training"]},{"cell_type":"code","metadata":{"id":"ehW86_XbYJQ6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1591958975066,"user_tz":-600,"elapsed":10108,"user":{"displayName":"Aditya Verma","photoUrl":"","userId":"11441793658136875754"}},"outputId":"719dd6be-ca54-45c9-8896-05b5cbaa9f82"},"source":["%cd /content/models/research\n","\n","import os\n","import shutil\n","import glob\n","import urllib.request\n","import tarfile\n","MODEL_FILE = MODEL + '.tar.gz'\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","DEST_DIR = '/content/models/research/pretrained_model'\n","\n","if not (os.path.exists(MODEL_FILE)):\n","    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","tar = tarfile.open(MODEL_FILE)\n","tar.extractall()\n","tar.close()\n","\n","os.remove(MODEL_FILE)\n","if (os.path.exists(DEST_DIR)):\n","    shutil.rmtree(DEST_DIR)\n","os.rename(MODEL, DEST_DIR)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ldnTeIlGYLM6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":200},"executionInfo":{"status":"ok","timestamp":1591958979520,"user_tz":-600,"elapsed":12490,"user":{"displayName":"Aditya Verma","photoUrl":"","userId":"11441793658136875754"}},"outputId":"ac5d4fd8-ad88-4f28-9e2c-d827f9beeae0"},"source":["!echo {DEST_DIR}\n","!ls -alh {DEST_DIR}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/models/research/pretrained_model\n","total 111M\n","drwxr-xr-x  3 345018 5000 4.0K Feb  1  2018 .\n","drwxr-xr-x 71 root   root 4.0K Jun 12 10:49 ..\n","-rw-r--r--  1 345018 5000   77 Feb  1  2018 checkpoint\n","-rw-r--r--  1 345018 5000  55M Feb  1  2018 frozen_inference_graph.pb\n","-rw-r--r--  1 345018 5000  51M Feb  1  2018 model.ckpt.data-00000-of-00001\n","-rw-r--r--  1 345018 5000  16K Feb  1  2018 model.ckpt.index\n","-rw-r--r--  1 345018 5000 5.5M Feb  1  2018 model.ckpt.meta\n","-rw-r--r--  1 345018 5000 3.2K Feb  1  2018 pipeline.config\n","drwxr-xr-x  3 345018 5000 4.0K Feb  1  2018 saved_model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-pzWHGTBYMCQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1591958979522,"user_tz":-600,"elapsed":11159,"user":{"displayName":"Aditya Verma","photoUrl":"","userId":"11441793658136875754"}},"outputId":"5674c0a3-5c78-4e2a-8aa3-af770ffba827"},"source":["fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n","fine_tune_checkpoint"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/models/research/pretrained_model/model.ckpt'"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"KRJUL367YOI1","colab_type":"code","colab":{}},"source":["import os\n","pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n","\n","assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6TfPiz1WYP8s","colab_type":"code","colab":{}},"source":["def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    return len(category_index.keys())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CLKU062abmPs","colab_type":"code","colab":{}},"source":["!protoc object_detection/protos/*.proto --python_out=."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vmVzX_TWYRJQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1591958982539,"user_tz":-600,"elapsed":1013,"user":{"displayName":"Aditya Verma","photoUrl":"","userId":"11441793658136875754"}},"outputId":"d889b9a5-c431-414d-bd16-919abcc64991"},"source":["\n","num_classes = get_num_classes(label_map_pbtxt_fname)\n","with open(pipeline_fname) as f:\n","    s = f.read()\n","with open(pipeline_fname, 'w') as f:\n","    \n","    # fine_tune_checkpoint\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","    \n","    # tfrecord files train and test.\n","    s = re.sub(\n","        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub(\n","        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n","\n","    # label_map_path\n","    s = re.sub(\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n","\n","    # Set training batch_size.\n","    s = re.sub('batch_size: [0-9]+',\n","               'batch_size: {}'.format(batch_size), s)\n","\n","    # Set training steps, num_steps\n","    s = re.sub('num_steps: [0-9]+',\n","               'num_steps: {}'.format(num_steps), s)\n","    \n","    # Set number of classes num_classes.\n","    s = re.sub('num_classes: [0-9]+',\n","               'num_classes: {}'.format(num_classes), s)\n","    f.write(s)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /content/models/research/object_detection/utils/label_map_util.py:132: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lPCHLTYMYSoa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1591958984843,"user_tz":-600,"elapsed":3298,"user":{"displayName":"Aditya Verma","photoUrl":"","userId":"11441793658136875754"}},"outputId":"0d0bfe82-bcf3-4108-dfd5-c671e707e44e"},"source":["!cat {pipeline_fname}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["# Faster R-CNN with Inception v2, configured for Oxford-IIIT Pets Dataset.\n","# Users should configure the fine_tune_checkpoint field in the train config as\n","# well as the label_map_path and input_path fields in the train_input_reader and\n","# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n","# should be configured.\n","\n","model {\n","  faster_rcnn {\n","    num_classes: 2\n","    image_resizer {\n","      keep_aspect_ratio_resizer {\n","        min_dimension: 600\n","        max_dimension: 1024\n","      }\n","    }\n","    feature_extractor {\n","      type: 'faster_rcnn_inception_v2'\n","      first_stage_features_stride: 16\n","    }\n","    first_stage_anchor_generator {\n","      grid_anchor_generator {\n","        scales: [0.25, 0.5, 1.0, 2.0]\n","        aspect_ratios: [0.5, 1.0, 2.0]\n","        height_stride: 16\n","        width_stride: 16\n","      }\n","    }\n","    first_stage_box_predictor_conv_hyperparams {\n","      op: CONV\n","      regularizer {\n","        l2_regularizer {\n","          weight: 0.0\n","        }\n","      }\n","      initializer {\n","        truncated_normal_initializer {\n","          stddev: 0.01\n","        }\n","      }\n","    }\n","    first_stage_nms_score_threshold: 0.0\n","    first_stage_nms_iou_threshold: 0.7\n","    first_stage_max_proposals: 300\n","    first_stage_localization_loss_weight: 2.0\n","    first_stage_objectness_loss_weight: 1.0\n","    initial_crop_size: 14\n","    maxpool_kernel_size: 2\n","    maxpool_stride: 2\n","    second_stage_box_predictor {\n","      mask_rcnn_box_predictor {\n","        use_dropout: false\n","        dropout_keep_probability: 1.0\n","        fc_hyperparams {\n","          op: FC\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.0\n","            }\n","          }\n","          initializer {\n","            variance_scaling_initializer {\n","              factor: 1.0\n","              uniform: true\n","              mode: FAN_AVG\n","            }\n","          }\n","        }\n","      }\n","    }\n","    second_stage_post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 0.0\n","        iou_threshold: 0.6\n","        max_detections_per_class: 100\n","        max_total_detections: 300\n","      }\n","      score_converter: SOFTMAX\n","    }\n","    second_stage_localization_loss_weight: 2.0\n","    second_stage_classification_loss_weight: 1.0\n","  }\n","}\n","\n","train_config: {\n","  batch_size: 12\n","  optimizer {\n","    momentum_optimizer: {\n","      learning_rate: {\n","        manual_step_learning_rate {\n","          initial_learning_rate: 0.0002\n","          schedule {\n","            step: 900000\n","            learning_rate: .00002\n","          }\n","          schedule {\n","            step: 1200000\n","            learning_rate: .000002\n","          }\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","    }\n","    use_moving_average: false\n","  }\n","  gradient_clipping_by_norm: 10.0\n","  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n","  from_detection_checkpoint: true\n","  load_all_detection_checkpoint_vars: true\n","  # Note: The below line limits the training process to 200K steps, which we\n","  # empirically found to be sufficient enough to train the pets dataset. This\n","  # effectively bypasses the learning rate schedule (the learning rate will\n","  # never decay). Remove the below line to train indefinitely.\n","  num_steps: 5000\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","}\n","\n","\n","train_input_reader: {\n","  tf_record_input_reader {\n","    input_path: \"/content/gdrive/My Drive/assign3/object_detection_demo/data/annotations/train.record\"\n","  }\n","  label_map_path: \"/content/gdrive/My Drive/assign3/object_detection_demo/data/annotations/label_map.pbtxt\"\n","}\n","\n","eval_config: {\n","  metrics_set: \"coco_detection_metrics\"\n","  num_examples: 1101\n","}\n","\n","eval_input_reader: {\n","  tf_record_input_reader {\n","    input_path: \"/content/gdrive/My Drive/assign3//object_detection_demo/data/annotations/test.record\"\n","  }\n","  label_map_path: \"/content/gdrive/My Drive/assign3/object_detection_demo/data/annotations/label_map.pbtxt\"\n","  shuffle: false\n","  num_readers: 1\n","}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e7Si5i_YYTiS","colab_type":"code","colab":{}},"source":["model_dir = 'training/'\n","# Optionally remove content in output model directory to fresh start.\n","!rm -rf {model_dir}\n","os.makedirs(model_dir, exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oB0G5_bVYUW8","colab_type":"text"},"source":["##tensorboard"]},{"cell_type":"markdown","metadata":{"id":"0VQtgnN63e2j","colab_type":"text"},"source":["Creation of tensorboard to easily display our results and training progress in real time"]},{"cell_type":"code","metadata":{"id":"LyNtLoIWYVUR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":233},"executionInfo":{"status":"ok","timestamp":1591958993811,"user_tz":-600,"elapsed":12238,"user":{"displayName":"Aditya Verma","photoUrl":"","userId":"11441793658136875754"}},"outputId":"d1ad84ab-1115-4a30-a377-74446a4b5583"},"source":["!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip -o ngrok-stable-linux-amd64.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-06-12 10:49:49--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","Resolving bin.equinox.io (bin.equinox.io)... 3.223.98.104, 52.22.23.115, 52.45.174.78, ...\n","Connecting to bin.equinox.io (bin.equinox.io)|3.223.98.104|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13773305 (13M) [application/octet-stream]\n","Saving to: ‘ngrok-stable-linux-amd64.zip.5’\n","\n","ngrok-stable-linux- 100%[===================>]  13.13M  5.98MB/s    in 2.2s    \n","\n","2020-06-12 10:49:52 (5.98 MB/s) - ‘ngrok-stable-linux-amd64.zip.5’ saved [13773305/13773305]\n","\n","Archive:  ngrok-stable-linux-amd64.zip\n","  inflating: ngrok                   \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EZ1RWygrYW8t","colab_type":"code","colab":{}},"source":["LOG_DIR = model_dir\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MS79HOQRYYRW","colab_type":"code","colab":{}},"source":["get_ipython().system_raw('./ngrok http 6006 &')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_VMYxlu2YYGi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1591958996173,"user_tz":-600,"elapsed":14562,"user":{"displayName":"Aditya Verma","photoUrl":"","userId":"11441793658136875754"}},"outputId":"5a989913-3509-4cab-87ab-ac14acb04062"},"source":["! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["https://67cab70a4df3.ngrok.io\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kjDiVJSYYZzJ","colab_type":"text"},"source":["##Training"]},{"cell_type":"code","metadata":{"id":"SaNApBWyYa04","colab_type":"code","colab":{}},"source":["!python /content/models/research/object_detection/model_main.py \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr \\\n","    --num_train_steps={num_steps} \\\n","    --num_eval_steps={num_eval_steps}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nzkCty-JID19","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}